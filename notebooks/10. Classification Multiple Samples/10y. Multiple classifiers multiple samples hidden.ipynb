{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "00d1b80c-d904-4986-91e2-123eee7a2ad6",
   "metadata": {},
   "source": [
    "### 0. Prereqs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6fd60258-b88d-42bc-adc8-7d760c50cb58",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-05T17:52:01.534215Z",
     "iopub.status.busy": "2024-03-05T17:52:01.533020Z",
     "iopub.status.idle": "2024-03-05T17:52:02.604608Z",
     "shell.execute_reply": "2024-03-05T17:52:02.604267Z",
     "shell.execute_reply.started": "2024-03-05T17:52:01.534197Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm.auto import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from mlxtend.feature_selection import (\n",
    "    SequentialFeatureSelector,\n",
    ")\n",
    "from mlxtend.evaluate import feature_importance_permutation\n",
    "from mlxtend.plotting import plot_sequential_feature_selection as plot_sfs\n",
    "from sklearn.utils.estimator_checks import check_estimator\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import cross_val_predict, train_test_split\n",
    "from sklearn.metrics import accuracy_score, f1_score, matthews_corrcoef\n",
    "import matplotlib.ticker as ticker\n",
    "import os\n",
    "\n",
    "os.chdir(\"../../\")\n",
    "from pathlib import Path\n",
    "import json\n",
    "\n",
    "import sys\n",
    "\n",
    "sys.path.append(\"scripts\")\n",
    "\n",
    "import utils\n",
    "import distclassipy as dcpy\n",
    "\n",
    "cd = dcpy.Distance()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6a6ba512-bafa-481b-8bb5-5e6971dd8f2a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-05T17:52:02.605194Z",
     "iopub.status.busy": "2024-03-05T17:52:02.605050Z",
     "iopub.status.idle": "2024-03-05T17:52:02.608675Z",
     "shell.execute_reply": "2024-03-05T17:52:02.608149Z",
     "shell.execute_reply.started": "2024-03-05T17:52:02.605183Z"
    },
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "with open(\"settings.txt\") as f:\n",
    "    settings_dict = json.load(f)\n",
    "np.random.seed(settings_dict[\"seed_choice\"])\n",
    "\n",
    "classification_letter = \"c\"\n",
    "classification_problem = settings_dict[\"classification_problem\"][classification_letter]\n",
    "classes_to_keep = settings_dict[\"classes_to_keep\"][classification_letter]\n",
    "results_subfolder = f\"{classification_letter}. {classification_problem}\"\n",
    "sns_dict = settings_dict[\"sns_dict\"]\n",
    "\n",
    "sns.set_theme(**sns_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "65a31dae-a482-479c-bcdf-1ca4d95badfc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-05T17:52:02.610026Z",
     "iopub.status.busy": "2024-03-05T17:52:02.609718Z",
     "iopub.status.idle": "2024-03-05T17:52:02.681004Z",
     "shell.execute_reply": "2024-03-05T17:52:02.680581Z",
     "shell.execute_reply.started": "2024-03-05T17:52:02.610012Z"
    },
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Load Data\n",
    "X_df_FULL = pd.read_csv(\"data/X_df.csv\", index_col=0)\n",
    "y_df_FULL = pd.read_csv(\"data/y_df.csv\", index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "71011c80-68da-400a-bbad-f610706a972f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-05T17:52:02.681516Z",
     "iopub.status.busy": "2024-03-05T17:52:02.681427Z",
     "iopub.status.idle": "2024-03-05T17:52:02.689848Z",
     "shell.execute_reply": "2024-03-05T17:52:02.688743Z",
     "shell.execute_reply.started": "2024-03-05T17:52:02.681507Z"
    },
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31\n"
     ]
    }
   ],
   "source": [
    "# Remove features to be dropped from previous notebook\n",
    "with open(os.path.join(\"results\", results_subfolder, \"drop_features.txt\")) as f:\n",
    "    bad_features = json.load(f)  # manually selected\n",
    "\n",
    "X_df_FULL = X_df_FULL.drop(bad_features, axis=1)\n",
    "\n",
    "print(X_df_FULL.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fa5d12e6-d9a6-49fc-824e-99211c3476e8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-05T17:52:02.692756Z",
     "iopub.status.busy": "2024-03-05T17:52:02.692300Z",
     "iopub.status.idle": "2024-03-05T17:52:02.699610Z",
     "shell.execute_reply": "2024-03-05T17:52:02.699175Z",
     "shell.execute_reply.started": "2024-03-05T17:52:02.692738Z"
    },
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Keep only current classes\n",
    "cl_keep_str = \"_\".join(classes_to_keep)\n",
    "\n",
    "y_df = y_df_FULL[y_df_FULL[\"class\"].isin(classes_to_keep)]\n",
    "X_df = X_df_FULL.loc[y_df.index]\n",
    "X = X_df.to_numpy()\n",
    "y = y_df.to_numpy().ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "309cbd3f-e837-4d62-80f2-82b85e08e09d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-05T17:52:02.702573Z",
     "iopub.status.busy": "2024-03-05T17:52:02.702388Z",
     "iopub.status.idle": "2024-03-05T17:52:02.708746Z",
     "shell.execute_reply": "2024-03-05T17:52:02.708281Z",
     "shell.execute_reply.started": "2024-03-05T17:52:02.702557Z"
    },
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "with open(os.path.join(\"results\", results_subfolder, \"best_common_features.txt\")) as f:\n",
    "    best_common_features = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dcd8202f-f2ce-4e10-9fc9-6118f70b9d51",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-05T17:52:02.713016Z",
     "iopub.status.busy": "2024-03-05T17:52:02.711727Z",
     "iopub.status.idle": "2024-03-05T17:52:02.718755Z",
     "shell.execute_reply": "2024-03-05T17:52:02.717401Z",
     "shell.execute_reply.started": "2024-03-05T17:52:02.712985Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "all_metrics = settings_dict[\"all_metrics\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "02014809-2cce-4a16-9c3e-6f4600c1264d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-05T17:53:58.449116Z",
     "iopub.status.busy": "2024-03-05T17:53:58.448399Z",
     "iopub.status.idle": "2024-03-05T17:54:31.121161Z",
     "shell.execute_reply": "2024-03-05T17:54:31.120625Z",
     "shell.execute_reply.started": "2024-03-05T17:53:58.449075Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting scikit-learn==1.3\n",
      "  Downloading scikit-learn-1.3.0.tar.gz (7.5 MB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.5/7.5 MB\u001b[0m \u001b[31m22.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m[36m0:00:01\u001b[0m\n",
      "\u001b[?25h  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25l|"
     ]
    }
   ],
   "source": [
    "!pip install scikit-learn==1.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb7dcf8c-18d3-436c-85fd-3ea3efbfac40",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for metric in tqdm(all_metrics, desc=\"Metric\", leave=True):\n",
    "\n",
    "    metric_str = utils.get_metric_name(metric)\n",
    "    print(\"*\" * 20, metric_str, \"*\" * 20)\n",
    "\n",
    "    lcdc1 = dcpy.DistanceMetricClassifier(\n",
    "        metric=metric,\n",
    "        scale=True,\n",
    "        central_stat=settings_dict[\"central_stat\"],\n",
    "        dispersion_stat=settings_dict[\"dispersion_stat\"],\n",
    "        calculate_kde=False,\n",
    "        calculate_1d_dist=False,\n",
    "    )\n",
    "\n",
    "    lcdc2 = dcpy.DistanceMetricClassifier(\n",
    "        metric=metric,\n",
    "        scale=True,\n",
    "        central_stat=settings_dict[\"central_stat\"],\n",
    "        dispersion_stat=settings_dict[\"dispersion_stat\"],\n",
    "        calculate_kde=False,\n",
    "        calculate_1d_dist=False,\n",
    "    )\n",
    "\n",
    "    X1, X2, y1, y2 = train_test_split(\n",
    "        X_df, y_df, test_size=0.5, stratify=y, random_state=settings_dict[\"seed_choice\"]\n",
    "    )\n",
    "\n",
    "    scoring = \"f1_macro\"\n",
    "\n",
    "    # Sequential Feature Selection first classifier\n",
    "    feat_selector1 = SequentialFeatureSelector(\n",
    "        lcdc1,\n",
    "        k_features=X1.shape[1],\n",
    "        scoring=scoring,\n",
    "        forward=True,\n",
    "        n_jobs=-1,\n",
    "        verbose=0,\n",
    "    ).fit(X1, y1)\n",
    "\n",
    "    # Sequential Feature Selection second classifier\n",
    "    feat_selector2 = SequentialFeatureSelector(\n",
    "        lcdc2,\n",
    "        k_features=X2.shape[1],\n",
    "        scoring=scoring,\n",
    "        forward=True,\n",
    "        n_jobs=-1,\n",
    "        verbose=0,\n",
    "    ).fit(X2, y2)\n",
    "\n",
    "    res_df1 = pd.DataFrame.from_dict(feat_selector1.get_metric_dict()).T\n",
    "    res_df1.index.name = \"num_feats\"\n",
    "    res_df1[\"avg_score\"] = res_df1[\"avg_score\"].astype(\"float\")\n",
    "    res_df1 = res_df1.sort_values(by=\"avg_score\", ascending=False)\n",
    "    res_df1.to_csv(\".tempres_df1.csv\")\n",
    "\n",
    "    res_df2 = pd.DataFrame.from_dict(feat_selector2.get_metric_dict()).T\n",
    "    res_df2.index.name = \"num_feats\"\n",
    "    res_df2[\"avg_score\"] = res_df2[\"avg_score\"].astype(\"float\")\n",
    "    res_df2 = res_df2.sort_values(by=\"avg_score\", ascending=False)\n",
    "    res_df2.to_csv(\".tempres_df2.csv\")\n",
    "\n",
    "    # Reloading to\n",
    "    sfs_df1 = pd.read_csv(\".tempres_df1.csv\", index_col=0)\n",
    "    feats_idx1, feats1 = utils.load_best_features(sfs_df1)\n",
    "    print(f\"{metric_str} LCDC 1: Selected {len(feats1)} features: {feats1}\")\n",
    "\n",
    "    sfs_df2 = pd.read_csv(\".tempres_df1.csv\", index_col=0)\n",
    "    feats_idx2, feats2 = utils.load_best_features(sfs_df2)\n",
    "    print(f\"{metric_str} LCDC 2: Selected {len(feats2)} features: {feats2}\")\n",
    "\n",
    "    HIDDENy_df = pd.read_csv(\"data/HIDDENy_df_multiclass.csv\", index_col=0)\n",
    "    HIDDENX_df = pd.read_csv(\"data/HIDDENX_df_multiclass.csv\", index_col=0)\n",
    "\n",
    "    HIDDENX_df1 = HIDDENX_df.loc[:, feats1]\n",
    "    HIDDENX_df1 = HIDDENX_df1.dropna()\n",
    "    HIDDENy_df1 = HIDDENy_df.loc[HIDDENX_df1.index]\n",
    "    HIDDENX1 = HIDDENX_df1.to_numpy()\n",
    "    HIDDENy1 = HIDDENy_df1.to_numpy().ravel()\n",
    "\n",
    "    HIDDENX_df2 = HIDDENX_df.loc[:, feats2]\n",
    "    HIDDENX_df2 = HIDDENX_df2.dropna()\n",
    "    HIDDENy_df2 = HIDDENy_df.loc[HIDDENX_df2.index]\n",
    "    HIDDENX2 = HIDDENX_df2.to_numpy()\n",
    "    HIDDENy2 = HIDDENy_df2.to_numpy().ravel()\n",
    "\n",
    "    # assert (HIDDENX2 == HIDDENX2).all()\n",
    "\n",
    "    lcdc1.fit(X1.loc[:, feats1].to_numpy(), y1)\n",
    "    lcdc2.fit(X2.loc[:, feats2].to_numpy(), y2)\n",
    "\n",
    "    HIDDENypred1 = lcdc1.predict(HIDDENX1)\n",
    "    HIDDENypred2 = lcdc2.predict(HIDDENX2)\n",
    "\n",
    "    acc1 = accuracy_score(y_true=HIDDENy1, y_pred=HIDDENypred1)\n",
    "    f1score1 = f1_score(y_true=HIDDENy1, y_pred=HIDDENypred1, average=\"macro\")\n",
    "    matthew_coef1 = matthews_corrcoef(y_true=HIDDENy1, y_pred=HIDDENypred1)\n",
    "\n",
    "    print(f\"{metric_str} LCDC 1: F1 Score = {f1score1:.3f}\")\n",
    "\n",
    "    acc2 = accuracy_score(y_true=HIDDENy2, y_pred=HIDDENypred2)\n",
    "    f1score2 = f1_score(y_true=HIDDENy2, y_pred=HIDDENypred2, average=\"macro\")\n",
    "    matthew_coef2 = matthews_corrcoef(y_true=HIDDENy2, y_pred=HIDDENypred2)\n",
    "\n",
    "    print(f\"{metric_str} LCDC 2: F1 Score = {f1score2:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9a346a0-836d-4061-93d8-c906ed3a89c3",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# results_dict = {}\n",
    "# for metric in tqdm(all_metrics, desc=\"Metric\", leave=True):\n",
    "#     metric_str = utils.get_metric_name(metric)\n",
    "#     locpath = os.path.join(\"results\", results_subfolder, \"distclassipy\", metric_str)\n",
    "#     print(\"*\" * 20, metric_str, \"*\" * 20)\n",
    "\n",
    "#     sfs_df = pd.read_csv(os.path.join(locpath, \"sfs_allfeatures.csv\"), index_col=0)\n",
    "#     feats_idx, feats = utils.load_best_features(sfs_df)\n",
    "\n",
    "#     lcdc1 = dcpy.DistanceMetricClassifier(\n",
    "#         metric=metric, scale=True,\n",
    "#         central_stat=settings_dict[\"central_stat\"],\n",
    "#         dispersion_stat=settings_dict[\"dispersion_stat\"],\n",
    "#         calculate_kde=False, calculate_1d_dist=False\n",
    "#     )\n",
    "\n",
    "#     lcdc2 = dcpy.DistanceMetricClassifier(\n",
    "#         metric=metric, scale=True,\n",
    "#         central_stat=settings_dict[\"central_stat\"],\n",
    "#         dispersion_stat=settings_dict[\"dispersion_stat\"],\n",
    "#         calculate_kde=False, calculate_1d_dist=False\n",
    "#     )\n",
    "\n",
    "#     X_df = X_df_FULL.loc[y_df.index]\n",
    "\n",
    "#     X_df = X_df.loc[:, feats]\n",
    "\n",
    "#     X = X_df.to_numpy()\n",
    "#     y = y_df.to_numpy().ravel()\n",
    "\n",
    "#     lcdc.fit(X, y)\n",
    "\n",
    "#     HIDDENy_df = pd.read_csv(\"data/HIDDENy_df_multiclass.csv\", index_col=0)\n",
    "#     HIDDENX_df = pd.read_csv(\"data/HIDDENX_df_multiclass.csv\", index_col=0)\n",
    "\n",
    "#     HIDDENX_df = HIDDENX_df.loc[:, feats]\n",
    "#     HIDDENX_df = HIDDENX_df.dropna()\n",
    "#     HIDDENy_df = HIDDENy_df.loc[HIDDENX_df.index]\n",
    "\n",
    "#     # HIDDENX = HIDDENX_df.to_numpy()\n",
    "#     # HIDDENy = HIDDENy_df.to_numpy().ravel()\n",
    "\n",
    "#     results_dict[metric_str] = {}\n",
    "#     choose_objs = 50\n",
    "\n",
    "#     for run_num in tqdm(range(1, 11), desc=\"Run Number\", leave=False):\n",
    "\n",
    "#         print(\"*\" * 10, f\"Run {run_num}\", \"*\" * 10)\n",
    "\n",
    "#         #### NEW - choose 100 from each class\n",
    "#         cury_df = HIDDENy_df.groupby(\"class\").sample(n=choose_objs).sample(frac=1) # Last sample for shuffling\n",
    "#         curX_df = HIDDENX_df.loc[cury_df.index]\n",
    "#         curX = curX_df.to_numpy()\n",
    "#         cury = cury_df.to_numpy().ravel()\n",
    "#         assert curX.shape[0]==cury.shape[0]\n",
    "\n",
    "#         results_dict[metric_str][run_num] = {}\n",
    "\n",
    "#         cury_pred = lcdc.predict_and_analyse(curX)\n",
    "\n",
    "#         acc = accuracy_score(y_true=cury, y_pred=cury_pred)\n",
    "#         f1score = f1_score(y_true=cury, y_pred=cury_pred, average=\"macro\")\n",
    "#         matthew_coef = matthews_corrcoef(y_true=cury, y_pred=cury_pred)\n",
    "\n",
    "\n",
    "#         results_dict[metric_str][run_num][\"acc\"] = acc\n",
    "#         results_dict[metric_str][run_num][\"f1score\"] = f1score\n",
    "#         results_dict[metric_str][run_num][\"matthew_coef\"] = matthew_coef\n",
    "#         results_dict[metric_str][run_num][\"features\"] = feats\n",
    "#         results_dict[metric_str][run_num][\"choose_objs\"] = choose_objs\n",
    "\n",
    "\n",
    "#         print(\"\\tExpected Score from training:\")\n",
    "#         print(\n",
    "#             f\"\\t\\tF1 = {sfs_df.loc[len(feats)]['avg_score']*100:.2f} ± {sfs_df.loc[len(feats)]['std_dev']*100:.2f}%\"\n",
    "#         )\n",
    "#         print(\"\\tActual score on hidden set:\")\n",
    "#         # print(f\"\\tAcc = {100*acc:.2f} %\")\n",
    "#         print(f\"\\t\\tF1 = {100*f1score:.2f} %\")\n",
    "\n",
    "#         ax = utils.plot_cm(y_true=cury, y_pred=cury_pred)\n",
    "#         plt.title(f\"{metric_str.title()} metric (hidden set)\")\n",
    "#         # plt.savefig(os.path.join(locpath, \"hidden_cm.pdf\"), bbox_inches=\"tight\")\n",
    "#         # plt.savefig(f\"hidden_cm/{metric_str}.pdf\",bbox_inches = 'tight')\n",
    "#         plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "386b7250-5d65-407d-99d8-e396e08ea076",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# # Flatten the dictionary\n",
    "# data = []\n",
    "# for method, values in results_dict.items():\n",
    "#     for key, val in values.items():\n",
    "#         val['metric'] = method\n",
    "#         val['run'] = key\n",
    "#         data.append(val)\n",
    "\n",
    "# # Convert to DataFrame\n",
    "# df = pd.DataFrame(data)\n",
    "# df = df.loc[:,['metric', 'run', 'f1score', 'acc', 'features', 'matthew_coef', 'choose_objs']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e8d244b-9d73-4bc4-a357-a02cba94f765",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# print(\"Mean\")\n",
    "# df.drop([\"run\"],axis=1).groupby(\"metric\").mean(numeric_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de5581f8-9095-4b34-89d8-c5e4f5c371a0",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# print(\"Mean\")\n",
    "# df.drop([\"run\"],axis=1).groupby(\"metric\").mean(numeric_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcb28913-abc0-4eae-a1ba-7b1663a1c887",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# print(\"Std deviation\")\n",
    "# df.drop([\"run\"],axis=1).groupby(\"metric\").std(numeric_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b73c68ed-6fb3-4468-a10d-bac710677f1b",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# df.drop([\"run\"],axis=1).groupby(\"metric\").describe().loc[:,[\n",
    "#     ('f1score', 'count'),\n",
    "#     ('f1score',  'mean'),\n",
    "#     ('f1score',   'std'),\n",
    "#     ('choose_objs', 'mean')\n",
    "\n",
    "#     # ('f1score',   'min'),\n",
    "#     # ('f1score',   '25%'),\n",
    "#     # ('f1score',   '50%'),\n",
    "#     # ('f1score',   '75%'),\n",
    "#     # ('f1score',   'max'),\n",
    "#     # ('selected_feats', 'count'),\n",
    "#     # ('selected_feats',  'mean'),\n",
    "#     # ('selected_feats',   'std'),\n",
    "#     # ('selected_feats',   'min'),\n",
    "#     # ('selected_feats',   '25%'),\n",
    "#     # ('selected_feats',   '50%'),\n",
    "#     # ('selected_feats',   '75%'),\n",
    "#     # ('selected_feats',   'max'),\n",
    "\n",
    "# ]].round(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f15ab55a-4c50-4b2b-90af-fc6db15b578f",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f7acc0d1-6f27-4060-af70-9005b572e527",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "source": [
    "---\n",
    "### TEMP\n",
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0af5e33f-0935-49c7-a1f4-5f723d1c3210",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "metric = \"canberra\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53e2910b-4b98-4b7c-917d-df46e3f21b26",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "metric_str = utils.get_metric_name(metric)\n",
    "print(\"*\" * 20, metric_str, \"*\" * 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e8098cb-60ea-489e-a86e-0187fcbcd75b",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "lcdc1 = dcpy.DistanceMetricClassifier(\n",
    "    metric=metric,\n",
    "    scale=True,\n",
    "    central_stat=settings_dict[\"central_stat\"],\n",
    "    dispersion_stat=settings_dict[\"dispersion_stat\"],\n",
    "    calculate_kde=False,\n",
    "    calculate_1d_dist=False,\n",
    ")\n",
    "\n",
    "lcdc2 = dcpy.DistanceMetricClassifier(\n",
    "    metric=metric,\n",
    "    scale=True,\n",
    "    central_stat=settings_dict[\"central_stat\"],\n",
    "    dispersion_stat=settings_dict[\"dispersion_stat\"],\n",
    "    calculate_kde=False,\n",
    "    calculate_1d_dist=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25b31e35-d399-44fd-a7d9-72802f622891",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "X1, X2, y1, y2 = train_test_split(\n",
    "    X_df, y_df, test_size=0.5, stratify=y, random_state=settings_dict[\"seed_choice\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd9c4c22-b51b-4b46-92a8-6e71436f68a5",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "scoring = \"f1_macro\"\n",
    "\n",
    "# Sequential Feature Selection first classifier\n",
    "feat_selector1 = SequentialFeatureSelector(\n",
    "    lcdc1,\n",
    "    k_features=X1.shape[1],\n",
    "    scoring=scoring,\n",
    "    forward=True,\n",
    "    n_jobs=-1,\n",
    "    verbose=0,\n",
    ").fit(X1, y1)\n",
    "\n",
    "# Sequential Feature Selection second classifier\n",
    "feat_selector2 = SequentialFeatureSelector(\n",
    "    lcdc2,\n",
    "    k_features=X2.shape[1],\n",
    "    scoring=scoring,\n",
    "    forward=True,\n",
    "    n_jobs=-1,\n",
    "    verbose=0,\n",
    ").fit(X2, y2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dabf0d30-075c-413b-b29c-e9e04bb04ef2",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "res_df1 = pd.DataFrame.from_dict(feat_selector1.get_metric_dict()).T\n",
    "res_df1.index.name = \"num_feats\"\n",
    "res_df1[\"avg_score\"] = res_df1[\"avg_score\"].astype(\"float\")\n",
    "res_df1 = res_df1.sort_values(by=\"avg_score\", ascending=False)\n",
    "res_df1.to_csv(\".tempres_df1.csv\")\n",
    "\n",
    "res_df2 = pd.DataFrame.from_dict(feat_selector2.get_metric_dict()).T\n",
    "res_df2.index.name = \"num_feats\"\n",
    "res_df2[\"avg_score\"] = res_df2[\"avg_score\"].astype(\"float\")\n",
    "res_df2 = res_df2.sort_values(by=\"avg_score\", ascending=False)\n",
    "res_df2.to_csv(\".tempres_df2.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65764781-aeae-48f4-9384-49905763fcf1",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Reloading to\n",
    "sfs_df1 = pd.read_csv(\".tempres_df1.csv\", index_col=0)\n",
    "feats_idx1, feats1 = utils.load_best_features(sfs_df1)\n",
    "print(f\"{metric_str} LCDC 1: Selected {len(feats1)} features: {feats1}\")\n",
    "\n",
    "sfs_df2 = pd.read_csv(\".tempres_df1.csv\", index_col=0)\n",
    "feats_idx2, feats2 = utils.load_best_features(sfs_df2)\n",
    "print(f\"{metric_str} LCDC 2: Selected {len(feats2)} features: {feats2}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "972576dd-7664-406f-8298-c4ba2473e02e",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# results_dict[metric_str][1][\"selected_feats\"] = feats1\n",
    "# results_dict[metric_str][2][\"selected_feats\"] = feats2\n",
    "\n",
    "# results_dict[metric_str][1][\"num_feats\"] = len(feats1)\n",
    "# results_dict[metric_str][2][\"num_feats\"] = len(feats2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b76bca0e-9221-4834-93ff-c9d492fdbcd6",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# def custom_plot_sfs(feat_selector, feats, title=\"\"):\n",
    "#     fig = plot_sfs(\n",
    "#         feat_selector.get_metric_dict(),\n",
    "#         kind=\"std_dev\",\n",
    "#         # color=sns.color_palette(\"Paired\")[1],\n",
    "#         # bcolor=sns.color_palette(\"Paired\")[0],\n",
    "#         color=sns.color_palette()[0],\n",
    "#         bcolor=\"#93aad0\",\n",
    "#         ylabel=\"F1 Score (%)\",  # scoring\n",
    "#     )\n",
    "#     fig[1].set_title(title) #Set 1 (first half)\n",
    "\n",
    "#     tick_freq = 5\n",
    "#     fig[1].set_xticks(\n",
    "#         [x for x in list(feat_selector.get_metric_dict().keys()) if x % tick_freq == 0]\n",
    "#     )\n",
    "\n",
    "#     # Temp fix to get % instead of 0-1 values\n",
    "#     fig[1].yaxis.set_major_formatter(\n",
    "#         ticker.FuncFormatter(lambda x, pos: \"{0:g}\".format(x * 100))\n",
    "#     )\n",
    "\n",
    "#     plt.locator_params(axis=\"y\", nbins=6)\n",
    "#     plt.axvline(x=len(feats), color=sns.color_palette()[3], label=\"Selected features\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95c41be4-8f9d-4ebc-afa4-c4ec5e45764c",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# custom_plot_sfs(feat_selector1, feats1,\"Set 1 (first half)\")\n",
    "\n",
    "# custom_plot_sfs(feat_selector2, feats2,\"Set 2 (first half)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23a34fd0-11b7-4c14-a3ae-dab197f49661",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "HIDDENy_df = pd.read_csv(\"data/HIDDENy_df_multiclass.csv\", index_col=0)\n",
    "HIDDENX_df = pd.read_csv(\"data/HIDDENX_df_multiclass.csv\", index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab365f9e-414b-4a90-8453-0490b8d21ad8",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "HIDDENX_df1 = HIDDENX_df.loc[:, feats1]\n",
    "HIDDENX_df1 = HIDDENX_df1.dropna()\n",
    "HIDDENy_df1 = HIDDENy_df.loc[HIDDENX_df1.index]\n",
    "HIDDENX1 = HIDDENX_df1.to_numpy()\n",
    "HIDDENy1 = HIDDENy_df1.to_numpy().ravel()\n",
    "\n",
    "HIDDENX_df2 = HIDDENX_df.loc[:, feats2]\n",
    "HIDDENX_df2 = HIDDENX_df2.dropna()\n",
    "HIDDENy_df2 = HIDDENy_df.loc[HIDDENX_df2.index]\n",
    "HIDDENX2 = HIDDENX_df2.to_numpy()\n",
    "HIDDENy2 = HIDDENy_df2.to_numpy().ravel()\n",
    "\n",
    "# assert (HIDDENX2 == HIDDENX2).all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f195f55a-307c-4490-8c38-769c9d2c0eee",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "lcdc1.fit(X1.loc[:, feats1].to_numpy(), y1)\n",
    "lcdc2.fit(X2.loc[:, feats2].to_numpy(), y2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64d257d1-84db-4f4c-8e60-5e0bd7d5db1a",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "HIDDENypred1 = lcdc1.predict(HIDDENX1)\n",
    "HIDDENypred2 = lcdc2.predict(HIDDENX2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36d94237-1706-467f-b9bd-e309a127332c",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "acc1 = accuracy_score(y_true=HIDDENy1, y_pred=HIDDENypred1)\n",
    "f1score1 = f1_score(y_true=HIDDENy1, y_pred=HIDDENypred1, average=\"macro\")\n",
    "matthew_coef1 = matthews_corrcoef(y_true=HIDDENy1, y_pred=HIDDENypred1)\n",
    "\n",
    "print(f\"{metric_str} LCDC 1: F1 Score = {f1score1:.3f}\")\n",
    "\n",
    "acc2 = accuracy_score(y_true=HIDDENy2, y_pred=HIDDENypred2)\n",
    "f1score2 = f1_score(y_true=HIDDENy2, y_pred=HIDDENypred2, average=\"macro\")\n",
    "matthew_coef2 = matthews_corrcoef(y_true=HIDDENy2, y_pred=HIDDENypred2)\n",
    "\n",
    "print(f\"{metric_str} LCDC 2: F1 Score = {f1score2:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0a86ff2-b423-4fc5-a6fd-7cdc055c4af3",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# results_dict[metric_str] = {}\n",
    "# choose_objs = 50\n",
    "\n",
    "# for run_num in tqdm(range(1, 11), desc=\"Run Number\", leave=False):\n",
    "\n",
    "#     print(\"*\" * 10, f\"Run {run_num}\", \"*\" * 10)\n",
    "\n",
    "#     #### NEW - choose 100 from each class\n",
    "#     cury_df = HIDDENy_df.groupby(\"class\").sample(n=choose_objs).sample(frac=1) # Last sample for shuffling\n",
    "#     curX_df = HIDDENX_df.loc[cury_df.index]\n",
    "#     curX = curX_df.to_numpy()\n",
    "#     cury = cury_df.to_numpy().ravel()\n",
    "#     assert curX.shape[0]==cury.shape[0]\n",
    "\n",
    "#     results_dict[metric_str][run_num] = {}\n",
    "\n",
    "#     cury_pred = lcdc.predict_and_analyse(curX)\n",
    "\n",
    "#     acc = accuracy_score(y_true=cury, y_pred=cury_pred)\n",
    "#     f1score = f1_score(y_true=cury, y_pred=cury_pred, average=\"macro\")\n",
    "#     matthew_coef = matthews_corrcoef(y_true=cury, y_pred=cury_pred)\n",
    "\n",
    "\n",
    "#     results_dict[metric_str][run_num][\"acc\"] = acc\n",
    "#     results_dict[metric_str][run_num][\"f1score\"] = f1score\n",
    "#     results_dict[metric_str][run_num][\"matthew_coef\"] = matthew_coef\n",
    "#     results_dict[metric_str][run_num][\"features\"] = feats\n",
    "#     results_dict[metric_str][run_num][\"choose_objs\"] = choose_objs\n",
    "\n",
    "\n",
    "#     print(\"\\tExpected Score from training:\")\n",
    "#     print(\n",
    "#         f\"\\t\\tF1 = {sfs_df.loc[len(feats)]['avg_score']*100:.2f} ± {sfs_df.loc[len(feats)]['std_dev']*100:.2f}%\"\n",
    "#     )\n",
    "#     print(\"\\tActual score on hidden set:\")\n",
    "#     # print(f\"\\tAcc = {100*acc:.2f} %\")\n",
    "#     print(f\"\\t\\tF1 = {100*f1score:.2f} %\")\n",
    "\n",
    "#     ax = utils.plot_cm(y_true=cury, y_pred=cury_pred)\n",
    "#     plt.title(f\"{metric_str.title()} metric (hidden set)\")\n",
    "#     # plt.savefig(os.path.join(locpath, \"hidden_cm.pdf\"), bbox_inches=\"tight\")\n",
    "#     # plt.savefig(f\"hidden_cm/{metric_str}.pdf\",bbox_inches = 'tight')\n",
    "#     plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8da80961-b1c5-41fc-b99c-dd3e596725c3",
   "metadata": {},
   "source": [
    "---\n",
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
